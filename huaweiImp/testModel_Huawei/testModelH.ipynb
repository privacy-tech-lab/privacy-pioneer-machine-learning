{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at dgoldelman/TinyBERT_General_4L_312D-finetuned-cola were not used when initializing TFBertForSequenceClassification: ['dropout_13']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at dgoldelman/TinyBERT_General_4L_312D-finetuned-cola.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "\n",
    "MODEL_NAME = 'dgoldelman/TinyBERT_General_4L_312D-finetuned-cola'\n",
    "\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 370). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: testModelHuawei/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: testModelHuawei/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given SavedModel SignatureDef contains the following input(s):\n",
      "  inputs['attention_mask'] tensor_info:\n",
      "      dtype: DT_INT32\n",
      "      shape: (-1, 312)\n",
      "      name: serving_default_attention_mask:0\n",
      "  inputs['input_ids'] tensor_info:\n",
      "      dtype: DT_INT32\n",
      "      shape: (-1, 312)\n",
      "      name: serving_default_input_ids:0\n",
      "The given SavedModel SignatureDef contains the following output(s):\n",
      "  outputs['logits'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1, 2)\n",
      "      name: StatefulPartitionedCall:0\n",
      "Method name is: tensorflow/serving/predict\n"
     ]
    }
   ],
   "source": [
    "callable = tf.function(model.call)\n",
    "concrete_function = callable.get_concrete_function([tf.TensorSpec([None, 312], tf.int32, name=\"input_ids\"),tf.TensorSpec([None, 312], tf.int32, name=\"attention_mask\")])\n",
    "\n",
    "tf.saved_model.save(model, 'testModelHuawei', signatures=concrete_function)\n",
    "!saved_model_cli show --dir testModelHuawei --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-25 12:19:38.305666: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-25 12:19:42.482609: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2022-03-25 12:19:42.483600: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2022-03-25 12:19:42.614508: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1149] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: Graph size after: 1138 nodes (1060), 1480 edges (1402), time = 84.751ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 3.126ms.\n",
      "\n",
      "2022-03-25 12:19:47.313883: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1149] Optimization results for grappler item: graph_to_optimize\n",
      "  debug_stripper: debug_stripper did nothing. time = 0.1ms.\n",
      "  model_pruner: Graph size after: 1034 nodes (-102), 1376 edges (-102), time = 149.099ms.\n",
      "  constant_folding: Graph size after: 956 nodes (-78), 1298 edges (-78), time = 247.746ms.\n",
      "  arithmetic_optimizer: Graph size after: 956 nodes (0), 1298 edges (0), time = 102.967ms.\n",
      "  dependency_optimizer: Graph size after: 880 nodes (-76), 1028 edges (-270), time = 59.666ms.\n",
      "  model_pruner: Graph size after: 880 nodes (0), 1028 edges (0), time = 51.575ms.\n",
      "  constant_folding: Graph size after: 880 nodes (0), 1028 edges (0), time = 130.376ms.\n",
      "  arithmetic_optimizer: Graph size after: 880 nodes (0), 1028 edges (0), time = 78.214ms.\n",
      "  dependency_optimizer: Graph size after: 880 nodes (0), 1028 edges (0), time = 41.229ms.\n",
      "  debug_stripper: debug_stripper did nothing. time = 5.833ms.\n",
      "  model_pruner: Graph size after: 880 nodes (0), 1028 edges (0), time = 20.908ms.\n",
      "  constant_folding: Graph size after: 880 nodes (0), 1028 edges (0), time = 110.527ms.\n",
      "  arithmetic_optimizer: Graph size after: 880 nodes (0), 1028 edges (0), time = 78.629ms.\n",
      "  dependency_optimizer: Graph size after: 880 nodes (0), 1028 edges (0), time = 38.356ms.\n",
      "  model_pruner: Graph size after: 880 nodes (0), 1028 edges (0), time = 28.139ms.\n",
      "  constant_folding: Graph size after: 880 nodes (0), 1028 edges (0), time = 110.33ms.\n",
      "  arithmetic_optimizer: Graph size after: 880 nodes (0), 1028 edges (0), time = 75.943ms.\n",
      "  dependency_optimizer: Graph size after: 880 nodes (0), 1028 edges (0), time = 37.439ms.\n",
      "\n",
      "2022-03-25 12:19:48.767607: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1149] Optimization results for grappler item: graph_to_optimize\n",
      "  remapper: Graph size after: 878 nodes (-2), 1026 edges (-2), time = 40.732ms.\n",
      "  constant_folding: Graph size after: 878 nodes (0), 1026 edges (0), time = 113.058ms.\n",
      "  arithmetic_optimizer: Graph size after: 878 nodes (0), 1026 edges (0), time = 78.068ms.\n",
      "  dependency_optimizer: Graph size after: 878 nodes (0), 1026 edges (0), time = 34.144ms.\n",
      "  remapper: Graph size after: 878 nodes (0), 1026 edges (0), time = 25.181ms.\n",
      "  constant_folding: Graph size after: 878 nodes (0), 1026 edges (0), time = 110.643ms.\n",
      "  arithmetic_optimizer: Graph size after: 878 nodes (0), 1026 edges (0), time = 79.42ms.\n",
      "  dependency_optimizer: Graph size after: 878 nodes (0), 1026 edges (0), time = 36.072ms.\n",
      "\n",
      "Writing weight file /Users/danielgoldelman/Desktop/privacy-tech-lab/privacy-pioneer-machine-learning/huaweiImp/testModel_Huawei/testModelHuawei_web/model.json...\n"
     ]
    }
   ],
   "source": [
    "!tensorflowjs_converter \\\n",
    "    --input_format=tf_saved_model \\\n",
    "    --output_format=tfjs_graph_model \\\n",
    "    --signature_name=serving_default \\\n",
    "    --saved_model_tags=serve \\\n",
    "    /Users/danielgoldelman/Desktop/privacy-tech-lab/privacy-pioneer-machine-learning/huaweiImp/testModel_Huawei/testModelHuawei \\\n",
    "    /Users/danielgoldelman/Desktop/privacy-tech-lab/privacy-pioneer-machine-learning/huaweiImp/testModel_Huawei/testModelHuawei_web"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
