{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial code for our ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installation of all important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install transformers\n",
    "! pip3 install datasets\n",
    "! pip3 install scipy sklearn\n",
    "! pip3 install huggingface_hub\n",
    "! pip3 install ipywidgets\n",
    "! pip3 install \"transformers==4.16.*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HuggingFace notebook login so that their functionality will work for pushing the completed model to the internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7820ac504ef4436a995d612668335e2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center>\\n<img src=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic setup and initial dataset loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to be performing the glue (General Language Understanding Evaluation) task to evaluate our understanding of the language. NOTE: This will change to be inferring things about the metrics of our data.\n",
    "\n",
    "We use huawei's TinyBERT as the pre-trained model that we will train on. It is 50mb, much smaller than the original 250mb of traditional BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"cola\"\n",
    "model_checkpoint = \"huawei-noah/TinyBERT_General_4L_312D\"\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading of our datasets, already parsed into train, test, validation by our direct input. NOTE: Subject to change when we move to full implimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-0890664f5098fa31\n",
      "Reusing dataset json (/Users/danielgoldelman/.cache/huggingface/datasets/json/default-0890664f5098fa31/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b)\n",
      "100%|██████████| 3/3 [00:00<00:00, 544.79it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('json', data_files={'train':\"DsetNew/tr.jsonl\", 'test':\"DsetNew/te.jsonl\", 'validation':\"DsetNew/va.jsonl\" }, )\n",
    "metric = load_metric('glue', 'cola')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View of our dataset. This shows that we have individual DatasetDicts containing ids, data, and our labels for that label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'data', 'label'],\n",
       "        num_rows: 80\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'data', 'label'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'data', 'label'],\n",
       "        num_rows: 11\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that we have 3 value fields for id, data, and label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': Value(dtype='int64', id=None),\n",
       " 'data': Value(dtype='string', id=None),\n",
       " 'label': Value(dtype='int64', id=None)}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Code to convert our label field to being a ClassLabel. Thus, the model can actually run our inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/danielgoldelman/.cache/huggingface/datasets/json/default-0890664f5098fa31/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-dfbb20676e6b298e.arrow\n",
      "Loading cached processed dataset at /Users/danielgoldelman/.cache/huggingface/datasets/json/default-0890664f5098fa31/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-d44793c1789265b3.arrow\n",
      "Loading cached processed dataset at /Users/danielgoldelman/.cache/huggingface/datasets/json/default-0890664f5098fa31/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-e9116d8af522ed68.arrow\n"
     ]
    }
   ],
   "source": [
    "for i in ['test','train','validation']:\n",
    "    new_features = dataset[i].features.copy()\n",
    "    new_features[\"label\"] = ClassLabel(num_classes=2, names=['True','False'], id=None)\n",
    "    dataset[i] = dataset[i].cast(new_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick peek into how our data actually looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 42, 'data': '{\"chatId\":null,\"ip\":\"<TARGET_IP>\",\"url\":\"https://writemyessaytoday.us/\",\"fingerprint\":\"0e817511c8c1644800d07b37e17a5e7a\",\"userAgent\":\"Mozilla/5.0 (Macintosh;', 'label': 1}\n",
      "{'id': 43, 'data': '1Imp\":\"\",\"_staticFo\":false,\"_jtags\":\"\",\"_l2fper\":[],\"_natpt\":41,\"_mbr\":1,\"_anc\":[],\"_im\":[],\"_ccTVal\":2000,\"_mNVisitIdData\":\"<TARGET_IP>\",\"_mNVsid\":\"DefVid\",\"_ip2c\":\"US\",\"_ip2sc\":\"GA\",\"viewid\":\"1646982560\",\"_dma\":\"524\",\"_ip2allsc\":\"GA\",\"_mxnf\":\"0\",\"_asn\":\"46562', 'label': 1}\n",
      "{'id': 44, 'data': 'var eti = \"1646982561\";var esi_ip = \"<TARGET_IP>\";var esi_ua = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/100.0.4', 'label': 1}\n",
      "{'id': 45, 'data': 'EDDED_PLAYER\",\"INNERTUBE_CLIENT_VERSION\":\"1.20220309.01.01\",\"INNERTUBE_CONTEXT\":{\"client\":{\"hl\":\"en\",\"gl\":\"US\",\"remoteHost\":\"<TARGET_IP>\",\"deviceMake\":\"Apple\",\"deviceModel\":\"\",\"visitorData\":\"Cgs1QmhjSDRpTjBLTSjj6quRBg%3D%3D\",\"userAgent\":\"Mozilla/5.0 (Macintosh;', 'label': 1}\n",
      "{'id': 48, 'data': '37.4,14.3-53\\n\\tC87.4,130.9,165,172.5,252.1,177.1c-1.6-7.8-2.6-15.9-2.6-24c0-57.8,46.8-104.9,104.9-104.9c30.2,0,57.5,12.7,76.7,<TARGET_LAT>\\n\\tc23.7-4.5,46.5-13.3,66.6-25.3c-7.8,24.4-24.4,44.8-46.1,57.8c21.1-2.3,41.6-8.1,60.4-16.2C497.7,118.3,479.8,136.8,459.4,151.7', 'label': 0}\n",
      "{'id': 49, 'data': '3.2 169.6,90.1 166.7,90.7 166.1,96.3 227.6,89.8 228.7,84.4 231.3,83.8 232.6,76.4 \\t\"/>\\n\\t<polygon fill=\"#7ABED6\" points=\"141.8,<TARGET_LAT> 166.1,96.3 166.7,90.7 141.6,27.9 \\t\"/>\\n\\t<polygon fill=\"#7ABED6\" points=\"142.9,20.7 142.9,27.9 169.6,90.1 170.2,83.2 \\t\"/>\\n\\t<po', 'label': 0}\n",
      "{'id': 50, 'data': '6-11.2a49 49 0 00-1.5-6.6c-.8-2.8-1.9-5.2-3-6.4-2.6-3-6.7-7.8-13.6-10.4a4 4 0 01-2.3-5.2z\" fill=\"#FF6100\"/><path d=\"M56 21.5L<TARGET_LAT> 73h106.3c12.1 2.4 18.2-6 18.2-25.2 0-28.8-44.8-48-102.8-26.4z\" fill=\"#F5A51C\"/><path d=\"M66.8 21.8C78.3 16 84.8 13 86.4 13c2.5 0 0', 'label': 0}\n",
      "{'id': 51, 'data': 'troke-linejoin=\"round\" stroke-miterlimit=\"2\" viewBox=\"0 0 125 125\" width=\"125\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"m-<TARGET_LAT> 60.172h84.001v72.445h-84.001z\" fill=\"#e0e0e0\" transform=\"matrix(1.48807306692 0 0 1.72543738752 51.693113736 -103.823282376)\"/><', 'label': 0}\n",
      "{'id': 54, 'data': '-98.8zM496 256c0 136.9-111.1 248-248 248S0 392.9 0 256 111.1 8 248 8s248 111.1 248 248zm-99.8 82.7L248 115.5 99.8 338.7h30.4l<TARGET_LAT>-51.7h168.6l<TARGET_LAT> 51.7h30.2z\"],adversal:[512,512,[],\"f36a\",\"M482.1 32H28.7C5.8 32 0 37.9 0 60.9v390.2C0 474.4 5.8 480 28.7 480h453.4', 'label': 0}\n",
      "{'id': 55, 'data': '81 13.5531 69.5292 13.2778 69.1745 12.9762C68.4367 12.4014 67.3534 12.0686 66.2031 12.0686\" fill=\"white\"/>\\n<path d=\"M94.5741 <TARGET_LAT>L84.9446 22.2614L93.25 13.5531C93.4736 13.307 93.5488 13.068 93.4644 12.8794C93.3801 12.6909 93.1494 12.586 92.8161 12.586H88.80', 'label': 0}\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(dataset[\"train\"][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to show random elements from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(\n",
    "        dataset\n",
    "    ), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset) - 1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset) - 1)\n",
    "        picks.append(pick)\n",
    "\n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, datasets.ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>data</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91</td>\n",
       "      <td>Buyback-Program.html\"&gt;Injured Gadgets - Lcd Buyback Program&lt;/a&gt;&lt;/b&gt;\\n&lt;br&gt;\\n&lt;span class=\"adcat\"&gt;\\nServices / Other\\n&lt;br&gt;Norcross, &lt;TARGET_REGION&gt;\\n&lt;/span&gt;\\n&lt;/td&gt;\\n&lt;td align=\"right\" width=\"100\"&gt;\\n&lt;/td&gt;\\n&lt;/tr&gt;\\n&lt;tr class=\"latest\"&gt;\\n&lt;td width=\"15\"&gt;\\n&lt;img src=\"images/bullet.gif\" al</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>176</td>\n",
       "      <td>3 78 3C36.5786 3 3 36.5786 3 78C3 119.421 36.5786 153 78 153ZM57 &lt;TARGET_LAT&gt;C57 45.6421 53.6421 49 49.5 49C45.3579 49 42 45.6421 42 &lt;TARGET_LAT&gt;C42 37.3579 45.3579 34 49.5 34C53.6421 34 57 37.3579 57 &lt;TARGET_LAT&gt;ZM83 74C83 79.5228 78.5228 84 73 84C67.4772 84 63 79.5228 63 74C63 68.4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>138</td>\n",
       "      <td>.5776-53.8624 20.48-76.3904 74.9568 91.7504 186.7776 152.3712 312.9344 158.72-2.6624-11.0592-3.8912-22.7328-3.8912-34.6112 0-&lt;TARGET_LNG&gt; 67.9936-151.7568 151.7568-151.7568 43.6224 0 83.1488 18.432 110.7968 47.9232 34.6112-6.7584 67.1744-19.456 96.4608-36.864-11</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>164</td>\n",
       "      <td>1Imp\":\"\",\"_staticFo\":false,\"_jtags\":\"\",\"_l2fper\":[],\"_natpt\":41,\"_mbr\":1,\"_anc\":[],\"_im\":[],\"_ccTVal\":2000,\"_mNVisitIdData\":\"&lt;TARGET_IP&gt;\",\"_mNVsid\":\"DefVid\",\"_ip2c\":\"US\",\"_ip2sc\":\"NY\",\"viewid\":\"1647048784\",\"_dma\":\"501\",\"_ip2allsc\":\"NY\",\"_mxnf\":\"0\",\"_asn\":\"32780</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69</td>\n",
       "      <td>.8325871 28.7276843 59.6359161 31.5299465 57.5965801 &lt;TARGET_LAT&gt; 54.3880248 35.0129818 50.0102502 35 44.2962249 35 40.3865265 &lt;TARGET_LAT&gt; 38.2811549 29.815594 37.0823886 27.6514148 36.5020826 25.1929666 36.6050149 22.7146793L36.6050149 5.86964437C36.768517 4.630</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>44</td>\n",
       "      <td>var eti = \"1646982561\";var esi_ip = \"&lt;TARGET_IP&gt;\";var esi_ua = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) HeadlessChrome/100.0.4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>120</td>\n",
       "      <td>=&gt; 'Atlanta',   'lat' =&gt; 33.749,   'long' =&gt; -84.388,   'postal_code' =&gt; NULL,   'region_code' =&gt; 'GA',   'region_name' =&gt; '&lt;TARGET_REGION&gt;', ) [] {\"class\":\"UserCountry\",\"request_id\":\"129c1\"}\\n\\n[2022-03-11 07:08:51] piwik.DEBUG: array (   'idvisitor' =&gt; '8ac6abfac1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>56</td>\n",
       "      <td>.0331C82.3077 25.0207 83.0546 25.6019 84.8818 26.0468L86.4436 26.4247C89.3522 27.1026 90.5606 28.254 90.5606 30.2974C90.5606 &lt;TARGET_LAT&gt; 88.4481 &lt;TARGET_LAT&gt; 85.088 &lt;TARGET_LAT&gt;C81.9443 &lt;TARGET_LAT&gt; 79.8217 &lt;TARGET_LAT&gt; 79.6846 30.4226L81.8562 30.4227Z\" fill=\"white\"/&gt;\\n&lt;path d=\"M95.14</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>151</td>\n",
       "      <td>63010713 36.50664 3.3713665 35.863085 2.30347703 34.6749016 1.65701853 33.3492173 1.3119847 32 1.29803778L32 0 49.6878409 0zM&lt;TARGET_LNG&gt; 0L&lt;TARGET_LNG&gt; 1.31556121C82.6841158 1.33369295 81.5443544 1.46931782 80.4269053 1.72034927 79.9590562 1.84975181 79.6450257 2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>116</td>\n",
       "      <td>dea\\\",\\\"name\\\":\\\"Gudea\\\",\\\"url\\\":\\\"//fonts.googleapis.com/css?family=Gudea:400,400i,700&amp;display=swap\\\",\\\"family\\\":\\\"'Gudea', &lt;TARGET_REGION&gt;, serif\\\",\\\"size\\\":16,\\\"weight\\\":400,\\\"weights\\\":[400,700],\\\"styles\\\":{\\\"letterSpacing\\\":\\\"normal\\\",\\\"textTransform\\\":\\\"none\\</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before feeding text to our model for inference, we must first preprocess the data. We do this by using Transformer's `Tokenizer` to convert the inputs to their corresponding ids in the pretrained vocabulary and generate all other inputs that the model requires.\n",
    "\n",
    "To do of this, we create our tokenizer with the `AutoTokenizer.from_pretrained` method, which will ensure:\n",
    "\n",
    "- we get a tokenizer that corresponds to the model architecture we want to use,\n",
    "- we download the vocabulary used when pretraining this specific checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example tokenization output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 7592, 1010, 2023, 2003, 1037, 6251, 999, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"Hello, this is a sentence!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5n/pfphrpmd5bq9sqnk02kwyzcw0000gn/T/ipykernel_35625/4166385883.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Data: {dataset['train'][0]['data']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"Data: {dataset['train'][0]['data']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual of the preprocessing working on our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"data\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1063, 1000, 11834, 3593, 1000, 1024, 19701, 1010, 1000, 12997, 1000, 1024, 1000, 1026, 4539, 1035, 12997, 1028, 1000, 1010, 1000, 24471, 2140, 1000, 1024, 1000, 16770, 1024, 1013, 1013, 4339, 8029, 7971, 4710, 3406, 10259, 1012, 2149, 1013, 1000, 1010, 1000, 4344, 16550, 1000, 1024, 1000, 1014, 2063, 2620, 16576, 22203, 2487, 2278, 2620, 2278, 16048, 22932, 17914, 2692, 2094, 2692, 2581, 2497, 24434, 2063, 16576, 2050, 2629, 2063, 2581, 2050, 1000, 1010, 1000, 5310, 4270, 3372, 1000, 1024, 1000, 9587, 5831, 4571, 1013, 1019, 1012, 1014, 1006, 22228, 1025, 102], [101, 1015, 5714, 2361, 1000, 1024, 1000, 1000, 1010, 1000, 1035, 10763, 14876, 1000, 1024, 6270, 1010, 1000, 1035, 1046, 15900, 2015, 1000, 1024, 1000, 1000, 1010, 1000, 1035, 1048, 2475, 22540, 2121, 1000, 1024, 1031, 1033, 1010, 1000, 1035, 14085, 13876, 1000, 1024, 4601, 1010, 1000, 1035, 16914, 2099, 1000, 1024, 1015, 1010, 1000, 1035, 2019, 2278, 1000, 1024, 1031, 1033, 1010, 1000, 1035, 10047, 1000, 1024, 1031, 1033, 1010, 1000, 1035, 10507, 9189, 2389, 1000, 1024, 2456, 1010, 1000, 1035, 24098, 11365, 25090, 25062, 2696, 1000, 1024, 1000, 1026, 4539, 1035, 12997, 1028, 1000, 1010, 1000, 1035, 24098, 15088, 3593, 1000, 1024, 1000, 13366, 17258, 1000, 1010, 1000, 1035, 12997, 2475, 2278, 1000, 1024, 1000, 2149, 1000, 1010, 1000, 1035, 12997, 2475, 11020, 1000, 1024, 1000, 11721, 1000, 1010, 1000, 3193, 3593, 1000, 1024, 1000, 28783, 2683, 2620, 17788, 16086, 1000, 1010, 1000, 1035, 1040, 2863, 1000, 1024, 1000, 4720, 2549, 1000, 1010, 1000, 1035, 12997, 2475, 8095, 11020, 1000, 1024, 1000, 11721, 1000, 1010, 1000, 1035, 25630, 2078, 2546, 1000, 1024, 1000, 1014, 1000, 1010, 1000, 1035, 2004, 2078, 1000, 1024, 1000, 4805, 26976, 2475, 102], [101, 13075, 3802, 2072, 1027, 1000, 28783, 2683, 2620, 17788, 2575, 2487, 1000, 1025, 13075, 9686, 2072, 1035, 12997, 1027, 1000, 1026, 4539, 1035, 12997, 1028, 1000, 1025, 13075, 9686, 2072, 1035, 25423, 1027, 1000, 9587, 5831, 4571, 1013, 1019, 1012, 1014, 1006, 22228, 1025, 13420, 6097, 9808, 1060, 2184, 1035, 2321, 1035, 1021, 1007, 6207, 8545, 2497, 23615, 1013, 5187, 2581, 1012, 4029, 1006, 1047, 11039, 19968, 1010, 2066, 16216, 19665, 1007, 2132, 3238, 20366, 1013, 2531, 1012, 1014, 1012, 1018, 102], [101, 3968, 5732, 1035, 2447, 1000, 1010, 1000, 5110, 28251, 2063, 1035, 7396, 1035, 2544, 1000, 1024, 1000, 1015, 1012, 16798, 11387, 14142, 2683, 1012, 5890, 1012, 5890, 1000, 1010, 1000, 5110, 28251, 2063, 1035, 6123, 1000, 1024, 1063, 1000, 7396, 1000, 1024, 1063, 1000, 1044, 2140, 1000, 1024, 1000, 4372, 1000, 1010, 1000, 1043, 2140, 1000, 1024, 1000, 2149, 1000, 1010, 1000, 6556, 15006, 2102, 1000, 1024, 1000, 1026, 4539, 1035, 12997, 1028, 1000, 1010, 1000, 5080, 2863, 3489, 1000, 1024, 1000, 6207, 1000, 1010, 1000, 5080, 5302, 9247, 1000, 1024, 1000, 1000, 1010, 1000, 10367, 2850, 2696, 1000, 1024, 1000, 1039, 5620, 2487, 4160, 2213, 2232, 22578, 13626, 13876, 3501, 16558, 3215, 3501, 3501, 2575, 28940, 15185, 2290, 1003, 7605, 1003, 7605, 1000, 1010, 1000, 5310, 4270, 3372, 1000, 1024, 1000, 9587, 5831, 4571, 1013, 1019, 1012, 1014, 1006, 22228, 1025, 102], [101, 4261, 1012, 1018, 1010, 2403, 1012, 1017, 1011, 5187, 1039, 2620, 2581, 1012, 1018, 1010, 7558, 1012, 1023, 1010, 13913, 1010, 18253, 1012, 1019, 1010, 22898, 1012, 1015, 1010, 18118, 1012, 1015, 2278, 1011, 1015, 1012, 1020, 1011, 1021, 1012, 1022, 1011, 1016, 1012, 1020, 1011, 2321, 1012, 1023, 1011, 1016, 1012, 1020, 1011, 2484, 2278, 2692, 1011, 5401, 1012, 1022, 1010, 4805, 1012, 1022, 1011, 9645, 1012, 1023, 1010, 9645, 1012, 1023, 1011, 9645, 1012, 1023, 2278, 14142, 1012, 1016, 1010, 1014, 1010, 5401, 1012, 1019, 1010, 2260, 1012, 1021, 1010, 6146, 1012, 1021, 1010, 1026, 4539, 1035, 2474, 2102, 1028, 29248, 2509, 1012, 1021, 1011, 1018, 1012, 1019, 1010, 4805, 1012, 1019, 1011, 2410, 1012, 1017, 1010, 5764, 1012, 1020, 1011, 2423, 1012, 1017, 2278, 1011, 1021, 1012, 1022, 1010, 2484, 1012, 1018, 1011, 2484, 1012, 1018, 1010, 4008, 1012, 1022, 1011, 4805, 1012, 1015, 1010, 5401, 1012, 1022, 2278, 17465, 1012, 1015, 1011, 1016, 1012, 1017, 1010, 4601, 1012, 1020, 1011, 1022, 1012, 1015, 1010, 3438, 1012, 1018, 1011, 2385, 1012, 1016, 2278, 26224, 2581, 1012, 1021, 1010, 12963, 1012, 1017, 1010, 4700, 2683, 1012, 1022, 1010, 15407, 1012, 1022, 1010, 3429, 2683, 1012, 1018, 1010, 16528, 1012, 1021, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_function(dataset[\"train\"][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply this function to all the sentences using the `map` method of our `dataset` object we created earlier. This applies the function on all the elements of all the splits in `dataset`, so our training, validation and testing data will be preprocessed in one single command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/danielgoldelman/.cache/huggingface/datasets/json/default-0890664f5098fa31/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-f55788b6127bd9c1.arrow\n",
      "Loading cached processed dataset at /Users/danielgoldelman/.cache/huggingface/datasets/json/default-0890664f5098fa31/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-e3ca9005b3c1aac9.arrow\n",
      "Loading cached processed dataset at /Users/danielgoldelman/.cache/huggingface/datasets/json/default-0890664f5098fa31/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b/cache-74ea2dc6c6428e57.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns added by tokenizer: ['attention_mask', 'input_ids', 'token_type_ids']\n"
     ]
    }
   ],
   "source": [
    "pre_tokenizer_columns = set(dataset[\"train\"].features)\n",
    "encoded_dataset = dataset.map(preprocess_function, batched=True)\n",
    "tokenizer_columns = list(set(encoded_dataset[\"train\"].features) - pre_tokenizer_columns)\n",
    "print(\"Columns added by tokenizer:\", tokenizer_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': Value(dtype='int64', id=None),\n",
       " 'data': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(num_classes=2, names=['True', 'False'], id=None),\n",
       " 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
       " 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
       " 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset[\"train\"].features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to convert the datasets to a `tf.data.Dataset` to convert our dataset into the required formats. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")\n",
    "\n",
    "validation_key = (\n",
    "    \"validation_mismatched\"\n",
    "    if task == \"mnli-mm\"\n",
    "    else \"validation_matched\"\n",
    "    if task == \"mnli\"\n",
    "    else \"validation\"\n",
    ")\n",
    "tf_train_dataset = encoded_dataset[\"train\"].to_tf_dataset(\n",
    "    columns=tokenizer_columns,\n",
    "    label_cols=[\"labels\"],\n",
    "    shuffle=True,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "tf_validation_dataset = encoded_dataset[validation_key].to_tf_dataset(\n",
    "    columns=tokenizer_columns,\n",
    "    label_cols=[\"labels\"],\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    "    collate_fn=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ({input_ids: (16, None), token_type_ids: (16, None), attention_mask: (16, None)}, (16,)), types: ({input_ids: tf.int64, token_type_ids: tf.int64, attention_mask: tf.int64}, tf.int64)>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForSequenceClassification: ['fit_denses.4.weight', 'fit_denses.4.bias', 'fit_denses.1.weight', 'fit_denses.0.bias', 'fit_denses.3.bias', 'fit_denses.3.weight', 'fit_denses.1.bias', 'fit_denses.2.weight', 'fit_denses.0.weight', 'fit_denses.2.bias']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForSequenceClassification\n",
    "import tensorflow as tf\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "num_labels = 2\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\n",
    "model_checkpoint, num_labels=num_labels, from_pt=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `create_optimizer` function creates an `AdamW` optimizer with weights and learning rate decay. This helps with training networks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import create_optimizer\n",
    "\n",
    "num_epochs = 5\n",
    "batches_per_epoch = len(encoded_dataset[\"train\"]) // batch_size\n",
    "total_train_steps = int(batches_per_epoch * num_epochs)\n",
    "\n",
    "optimizer, schedule = create_optimizer(\n",
    "    init_lr=2e-5, num_warmup_steps=0, num_train_steps=total_train_steps\n",
    ")\n",
    "model.compile(optimizer=optimizer, loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the `metric` function from earlier in the code to compute metrics from the predictions. \n",
    "\n",
    "We wrap the metric computation in a `KerasMetricCallback`, which will compute the metrric on the validation set each epoc, which helps the `Tensorboard` and `EarlyStopping` callbacks.\n",
    "\n",
    "NOTE: We may want to switch to a `Accuracy` callback instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.keras_callbacks import KerasMetricCallback\n",
    "\n",
    "metric_name = (\n",
    "    \"pearson\"\n",
    "    if task == \"stsb\"\n",
    "    else \"matthews_correlation\"\n",
    "    if task == \"cola\"\n",
    "    else \"accuracy\"\n",
    ")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_predictions):\n",
    "    predictions, labels = eval_predictions\n",
    "    if task != \"stsb\":\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "    else:\n",
    "        predictions = predictions[:, 0]\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "\n",
    "metric_callback = KerasMetricCallback(\n",
    "    metric_fn=compute_metrics, eval_dataset=tf_validation_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must change the environment to allow for posting to HuggingFace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now finetune the model by calling the `fit` method. We add the `PushToHubCallback` to place the model in the HuggingFace Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielgoldelman/Desktop/privacy-tech-lab/privacy-pioneer-machine-learning/ourHua_d1/text_classification_model_save is already a clone of https://huggingface.co/dgoldelman/TinyBERT_General_4L_312D-finetuned-cola-pp-hua-d1. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5/5 [==============================] - 19s 3s/step - loss: 0.6792 - val_loss: 0.6583 - matthews_correlation: 0.0000e+00\n",
      "Epoch 2/3\n",
      "5/5 [==============================] - 9s 2s/step - loss: 0.6478 - val_loss: 0.6265 - matthews_correlation: 0.0000e+00\n",
      "Epoch 3/3\n",
      "5/5 [==============================] - 9s 2s/step - loss: 0.6237 - val_loss: 0.6024 - matthews_correlation: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upload file tf_model.h5:   0%|          | 32.0k/54.9M [00:00<?, ?B/s]\n",
      "Upload file tf_model.h5:  99%|█████████▊| 54.1M/54.9M [00:44<00:00, 1.44MB/s]To https://huggingface.co/dgoldelman/TinyBERT_General_4L_312D-finetuned-cola-pp-hua-d1\n",
      "   b4958fd..5acf7c4  main -> main\n",
      "\n",
      "Upload file tf_model.h5: 100%|██████████| 54.9M/54.9M [00:45<00:00, 1.27MB/s]\n",
      "Upload file logs/train/events.out.tfevents.1648825112.Daniels-Computer.local.65897.5.v2: 100%|██████████| 973k/973k [00:45<00:00, 21.3kB/s]\n",
      "\n",
      "\u001b[A\n",
      "Upload file logs/validation/events.out.tfevents.1648825125.Daniels-Computer.local.65897.6.v2: 100%|██████████| 503/503 [00:45<?, ?B/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe2048147c0>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers.keras_callbacks import PushToHubCallback\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "push_to_hub_model_id = f\"{model_name}-finetuned-{task}-pp-hua-d1\"\n",
    "\n",
    "tensorboard_callback = TensorBoard(log_dir=\"./text_classification_model_save/logs\")\n",
    "\n",
    "early_stopping_callback = EarlyStopping(patience=1)\n",
    "\n",
    "push_to_hub_callback = PushToHubCallback(\n",
    "    output_dir=\"./text_classification_model_save\",\n",
    "    tokenizer=tokenizer,\n",
    "    hub_model_id=push_to_hub_model_id,\n",
    ") \n",
    "\n",
    "callbacks = [metric_callback, tensorboard_callback, push_to_hub_callback, early_stopping_callback]\n",
    "\n",
    "model.fit(\n",
    "    tf_train_dataset,\n",
    "    validation_data=tf_validation_dataset,\n",
    "    epochs=3,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
